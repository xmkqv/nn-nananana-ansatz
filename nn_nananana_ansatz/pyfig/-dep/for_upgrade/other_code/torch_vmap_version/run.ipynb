{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload \n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["init PlugIn classes\n","updating configuration\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: ff7b55a stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","running script\n","setting exp_path\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: ff7b55a stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n"]},{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxmax1\u001b[0m (\u001b[33mhwat\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>dump/exp/junk-45/GikwPCH/wandb/run-20230102_094530-1au7d6p5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/hwat/hwat/runs/1au7d6p5\" target=\"_blank\">iconic-vortex-298</a></strong> to <a href=\"https://wandb.ai/hwat/hwat\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ü§ñ 1 GPUs available\n"]},{"data":{"text/plain":["' copy lines and run in analysis while the exp is live '"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["### Distribution ‚ú® ‚ùá Demo üí™ ### \n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","### fancy logging variables, philosophically reminding us of the goal ###\n","fancy = dict(\n","\t\tpe\t\t= r'$V(X)',    \t\t\t\t\n","\t\tke\t\t= r'$\\nabla^2',    \t\t\n","\t\te\t\t= r'$E',\t\t\t\t\t\t\n","\t\tlog_psi\t= r'$\\log\\psi', \t\t\t\n","\t\tdeltar\t= r'$\\delta_\\mathrm{r}',\t\n","\t\tx\t\t= r'$r_\\mathrm{e}',\n",")\n","\n","### pyfig ###\n","from pyfig import Pyfig\n","\n","# arg = {\n","# \t'a_z':[4,], \n","# \t'n_b': 256, \n","# \t'n_sv': 16, \n","# \t'n_pv': 16, \n","# \t'n_corr': 20, \n","# \t'n_step': 100000, \n","# \t'log_metric_step': 1, \n","# \t'exp_name':'demo',\n","# }\n","\n","c = Pyfig(wb_mode='online', submit=False, run_sweep=False, notebook=True)\n","\n","n_device = c.n_device\n","print(f'ü§ñ {n_device} GPUs available')\n","\n","\n","# from print import print\n","# print(c.d)\n","\n","\"\"\" live plotting in another notebook \"\"\"\n","\"\"\" copy lines and run in analysis while the exp is live \"\"\"\n","# api = wandb.Api()\n","# run = api.run(\"<run-here>\")\n","# c = run.config\n","# h = run.history()\n","# s = run.summary\n","\n","\n","# SOLVE THE CONUNDRUM "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:  cuda n_dev:  1 device cuda name:  NVIDIA TITAN Xp\n"]}],"source":["import torch\n","torch.manual_seed(1234)\n","torch.set_default_tensor_type(torch.DoubleTensor)   # ‚ùó Ensure works when default not set AND can go float32 or 64\n","n_device = torch.cuda.device_count()\n","current_device = torch.cuda.current_device()\n","device = torch.cuda.device(0)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device_name = torch.cuda.get_device_name(0)\n","print('cuda: ', device, 'n_dev: ', n_device, 'device', device, 'name: ', device_name)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["r:  torch.Size([1, 256, 4, 3]) torch.float64\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: ff7b55a stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","anti-symmetry:  -17.823637621332686 -17.823637621332686 1.0 -1.0\n","anti-symmetry:  -17.823637621332686 -17.823637621332686 1.0 -1.0\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: ff7b55a stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","{'TMP': PosixPath('dump/tmp'),\n"," 'cap': 3,\n"," 'commit_id': 'ff7b55a',\n"," 'data': {'a': tensor([[0., 0., 0.]], device='cuda:0'),\n","          'a_z': tensor([4.], device='cuda:0'),\n","          'acc_target': 0.5,\n","          'charge': 0,\n","          'n_b': 256,\n","          'n_corr': 20,\n","          'n_d': 2,\n","          'n_e': 4,\n","          'n_equil': 10000,\n","          'n_u': 2,\n","          'spin': 0},\n"," 'debug': False,\n"," 'dtype': 'float32',\n"," 'dump': PosixPath('dump'),\n"," 'env': 'lumi',\n"," 'exp_name': 'junk',\n"," 'exp_path': PosixPath('dump/exp/junk-45/GikwPCH'),\n"," 'git_branch': 'main',\n"," 'git_remote': 'origin',\n"," 'hostname': 'oceanus ',\n"," 'log_metric_step': 10,\n"," 'log_state_step': 10,\n"," 'model': {'ke_method': 'ke_method',\n","           'n_det': 1,\n","           'n_fb': 2,\n","           'n_fbv': 128,\n","           'n_pv': 16,\n","           'n_sv': 32,\n","           'terms_p_emb': ['rr', 'rr_len'],\n","           'terms_s_emb': ['ra', 'ra_len'],\n","           'with_sign': False},\n"," 'n_device': 1,\n"," 'n_step': 10000,\n"," 'project': 'hwat',\n"," 'project_dir': PosixPath('/home/amawi/projects/hwat'),\n"," 'run_dir': PosixPath('projects/hwat'),\n"," 'run_name': 'run.py',\n"," 'run_sweep': False,\n"," 'sbatch': 'module purge\\n'\n","           'source ~/.bashrc\\n'\n","           'module load GCC\\n'\n","           'module load CUDA/11.4.1\\n'\n","           'module load cuDNN/8.2.2.26-CUDA-11.4.1\\n'\n","           'conda activate lumi',\n"," 'seed': 808017424,\n"," 'server': 'svol.fysik.dtu.dk',\n"," 'server_project_dir': PosixPath('projects/hwat'),\n"," 'slurm': {'cpus_per_task': 1,\n","           'error': PosixPath('dump/exp/junk-45/GikwPCH/e-%j.err'),\n","           'gres': 'gpu:RTX3090:1',\n","           'job_name': 'junk',\n","           'mail_type': 'FAIL',\n","           'nodes': 1,\n","           'ntasks': 8,\n","           'output': PosixPath('dump/exp/junk-45/GikwPCH/o-%j.out'),\n","           'partition': 'sm3090',\n","           'time': '0-12:00:00'},\n"," 'submit': False,\n"," 'sweep': {'method': 'grid',\n","           'name': 'demo',\n","           'parameters': {'n_b': {'values': [16, 32, 64]}}},\n"," 'sweep_id': '',\n"," 'sweep_path_id': '',\n"," 'user': 'amawi',\n"," 'wandb_c': {'entity': 'hwat',\n","             'job_type': 'training',\n","             'name': 'junk',\n","             'program': PosixPath('projects/hwat/run.py')},\n"," 'wb_mode': 'online'}\n"]}],"source":["### model ###\n","from functools import partial\n","from hwat_func import Ansatz_fb\n","from torch import nn\n","\n","import print\n","\n","from hwat_func import init_r, get_center_points\n","\n","dtype = torch.randn(1).dtype\n","c._convert(device, dtype=dtype)\n","\n","n_e = c.data.n_e\n","center_points = get_center_points(c.data.n_e, c.app.a)\n","r = init_r(n_device, c.data.n_b, c.data.n_e, center_points, std=0.1).to(device)\n","dtype = r.dtype\n","\n","print('r: ', r.shape, r.dtype)\n","r = r[0]  # single batch, single gpu, ‚ùó how to multi gpu\n","\n","model_check = c.partial(Ansatz_fb, with_sign=True).to(device)\n","r_swap = r[0, [1,0]+[i for i in range(2, c.data.n_e)]]\n","lp0, s0 = model_check(r[0])\n","lp1, s1 = model_check(r_swap)\n","print('anti-symmetry: ', lp0.item(), lp0.item(), s0.item(), s1.item())\n","r_swap = r[0, [i for i in range(0, c.data.n_e-2)]+[n_e-1,n_e-2]]\n","lp1, s1 = model_check(r_swap)\n","print('anti-symmetry: ', lp0.item(), lp0.item(), s0.item(), s1.item())\n","\n","print.print(c.d)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["exp/actual | \n","\tcps    : (4, 3)/torch.Size([4, 3])\n","\tr      : (1, 256, 4, 3)/torch.Size([256, 4, 3])\n","\tdeltar : (1,)/torch.Size([1])\n","\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: ff7b55a stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","Go see: https://wandb.ai/hwat/hwat/runs/1au7d6p5\n","tensor(356.9424, device='cuda:0')\n","tensor([[-0.2679,  0.5838, -0.0088],\n","        [ 0.6103, -0.4952,  0.1720]], device='cuda:0')\n","{'e': '-10.8709', 'ke': '8.9920', 'pe': '-19.8629', 'r': '-0.0187', 'step': 11}\n","tensor(1275.8552, device='cuda:0')\n","tensor([[-0.8717,  0.5601, -0.0271],\n","        [ 0.6196,  1.2960, -1.5286]], device='cuda:0')\n","{'e': '-6.1854', 'ke': '6.9125', 'pe': '-13.0980', 'r': '-0.0187', 'step': 22}\n","tensor(1423.5954, device='cuda:0')\n","tensor([[-0.6559, -0.6175, -0.7900],\n","        [ 1.4435,  0.4194, -0.2540]], device='cuda:0')\n","{'e': '-8.5393', 'ke': '4.0690', 'pe': '-12.6083', 'r': '0.0021', 'step': 33}\n","tensor(1542.9798, device='cuda:0')\n","tensor([[-0.7745,  0.5771,  1.6580],\n","        [ 0.4132,  0.5454,  0.2341]], device='cuda:0')\n","{'e': '-8.3691', 'ke': '4.6204', 'pe': '-12.9894', 'r': '-0.0031', 'step': 44}\n","tensor(1557.1666, device='cuda:0')\n","tensor([[-0.5469,  1.0631, -0.4112],\n","        [ 1.5749,  1.0861, -0.8234]], device='cuda:0')\n","{'e': '-8.2466', 'ke': '4.9009', 'pe': '-13.1475', 'r': '0.0119', 'step': 55}\n","tensor(1302.6580, device='cuda:0')\n","tensor([[-0.8774,  1.5916, -1.3219],\n","        [ 0.3522, -0.5042, -0.2197]], device='cuda:0')\n","{'e': '-7.3663', 'ke': '4.7994', 'pe': '-12.1658', 'r': '0.0242', 'step': 66}\n","tensor(1240.9626, device='cuda:0')\n","tensor([[ 1.2510, -1.5906, -0.4884],\n","        [-0.2802, -0.2098,  0.6002]], device='cuda:0')\n","{'e': '-8.5448', 'ke': '4.8107', 'pe': '-13.3555', 'r': '-0.0162', 'step': 78}\n","tensor(1178.9845, device='cuda:0')\n","tensor([[ 0.9689,  0.0669, -0.3807],\n","        [-0.4049,  0.2507,  0.0333]], device='cuda:0')\n","{'e': '-8.4147', 'ke': '4.6557', 'pe': '-13.0704', 'r': '0.0003', 'step': 89}\n","tensor(1175.0774, device='cuda:0')\n","tensor([[ 0.4217, -0.7330,  0.5059],\n","        [-0.4863,  0.6112,  0.6540]], device='cuda:0')\n","{'e': '-8.7865', 'ke': '4.5377', 'pe': '-13.3241', 'r': '0.0063', 'step': 100}\n","tensor(1533.5615, device='cuda:0')\n","tensor([[ 0.3688, -0.1707,  0.1762],\n","        [-0.2996, -0.2169,  0.3836]], device='cuda:0')\n","{'e': '-7.7472', 'ke': '4.0699', 'pe': '-11.8172', 'r': '0.0137', 'step': 113}\n","tensor(1558.2607, device='cuda:0')\n","tensor([[ 0.8207, -1.2544,  1.1361],\n","        [-0.8596,  0.1915, -0.6828]], device='cuda:0')\n","{'e': '-8.4011', 'ke': '4.5397', 'pe': '-12.9408', 'r': '0.0066', 'step': 127}\n","tensor(1709.4429, device='cuda:0')\n","tensor([[ 0.0402,  0.0335, -0.1046],\n","        [ 0.1682, -0.0310, -0.8415]], device='cuda:0')\n","{'e': '-57.0697',\n"," 'ke': '-44.2011',\n"," 'pe': '-12.8686',\n"," 'r': '0.0132',\n"," 'step': 141}\n","tensor(1915.9052, device='cuda:0')\n","tensor([[ 0.1717,  0.4164,  0.2599],\n","        [ 1.3831, -1.0778,  0.4046]], device='cuda:0')\n","{'e': '-7.8336', 'ke': '4.4149', 'pe': '-12.2486', 'r': '0.0036', 'step': 154}\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m r \u001b[39m=\u001b[39m keep_around_points(r, center_points, l\u001b[39m=\u001b[39m\u001b[39m2.\u001b[39m) \u001b[39mif\u001b[39;00m step \u001b[39m<\u001b[39m \u001b[39m200\u001b[39m \u001b[39melse\u001b[39;00m r\n\u001b[1;32m     70\u001b[0m \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m ke \u001b[39m=\u001b[39m compute_ke_b(model_rv, r)\n\u001b[1;32m     72\u001b[0m pe \u001b[39m=\u001b[39m compute_pe_b(r, c\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39ma, c\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39ma_z)\n\u001b[1;32m     73\u001b[0m \u001b[39m# print(pe.shape, ke.shape)\u001b[39;00m\n","File \u001b[0;32m~/projects/hwat/hwat_func.py:232\u001b[0m, in \u001b[0;36mcompute_ke_b\u001b[0;34m(model_rv, r, ke_method)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m ke_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjvp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    231\u001b[0m \tgrad_fn \u001b[39m=\u001b[39m grad(model_rv)\n\u001b[0;32m--> 232\u001b[0m \tjvp_all \u001b[39m=\u001b[39m [jvp(grad_fn, (r_flat,), (eyes[:, i],)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_jvp)]  \u001b[39m# grad out, jvp\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \te_jvp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([a[:, i]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m b[:, i] \u001b[39mfor\u001b[39;00m i, (a,b) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(jvp_all)])\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[39m#  (primal[:, i]**2).squeeze() + (tangent[:, i]).squeeze()\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# primal, tangent = jax.jvp(grad_fn, (r,), (eye[..., i],))  \u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m# \treturn val + (primal[:, i]**2).squeeze() + (tangent[:, i]).squeeze()\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m# return (- 0.5 * jax.lax.fori_loop(0, n_jvp, _body_fun, jnp.zeros(n_b,))).squeeze()\u001b[39;00m\n","File \u001b[0;32m~/projects/hwat/hwat_func.py:232\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m ke_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjvp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    231\u001b[0m \tgrad_fn \u001b[39m=\u001b[39m grad(model_rv)\n\u001b[0;32m--> 232\u001b[0m \tjvp_all \u001b[39m=\u001b[39m [jvp(grad_fn, (r_flat,), (eyes[:, i],)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_jvp)]  \u001b[39m# grad out, jvp\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \te_jvp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([a[:, i]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m b[:, i] \u001b[39mfor\u001b[39;00m i, (a,b) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(jvp_all)])\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[39m#  (primal[:, i]**2).squeeze() + (tangent[:, i]).squeeze()\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# primal, tangent = jax.jvp(grad_fn, (r,), (eye[..., i],))  \u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m# \treturn val + (primal[:, i]**2).squeeze() + (tangent[:, i]).squeeze()\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m# return (- 0.5 * jax.lax.fori_loop(0, n_jvp, _body_fun, jnp.zeros(n_b,))).squeeze()\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/lumi/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:859\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m@exposed_in\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtorch.func\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[39m*\u001b[39m, strict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, has_aux: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    809\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[39m    Standing for the Jacobian-vector product, returns a tuple containing\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[39m    the output of `func(*primals)` and the \"Jacobian of ``func`` evald at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m \n\u001b[1;32m    857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m _jvp_with_argnums(func, primals, tangents, argnums\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, strict\u001b[39m=\u001b[39;49mstrict, has_aux\u001b[39m=\u001b[39;49mhas_aux)\n","File \u001b[0;32m~/.conda/envs/lumi/lib/python3.9/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.conda/envs/lumi/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:908\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    906\u001b[0m     primals \u001b[39m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    907\u001b[0m     duals \u001b[39m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m--> 908\u001b[0m result_duals \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mduals)\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m    910\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(result_duals, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(result_duals) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n","File \u001b[0;32m~/.conda/envs/lumi/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1315\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m   1314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1315\u001b[0m     results \u001b[39m=\u001b[39m grad_and_value(func, argnums, has_aux\u001b[39m=\u001b[39;49mhas_aux)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m   1317\u001b[0m         grad, (_, aux) \u001b[39m=\u001b[39m results\n","File \u001b[0;32m~/.conda/envs/lumi/lib/python3.9/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["### train step ###\n","from hwat_func import compute_ke_b, compute_pe_b\n","from functorch import vmap, make_functional, grad\n","import functorch\n","\n","# def train_step(model, model_v, _params, r_step):\n","\n","\t\n","\n","# \tv_tr = dict(\n","# \t\tparams=params, \n","#   \t\tgrads=grads,\n","# \t\te=e, pe=pe, ke=ke,\n","# \t\tr=r_step\n","# \t)\n","# \treturn v_tr\n","\n","\n","r = r.to(device)\n","center_points = center_points.to(device)\n","\n","# v_tr = train_step(model, params, r)\n","# print.print({k:v.shape if isinstance(v, torch.Tensor) else len(v) for k,v in v_tr.items()})\n","\n","### init variables ###\n","deltar = torch.tensor([0.02]).to(device)\n","\n","print(f\"\"\"exp/actual | \n","\tcps    : {(c.data.n_e,3)}/{center_points.shape}\n","\tr      : {(c.n_device, c.data.n_b, c.data.n_e, 3)}/{r.shape}\n","\tdeltar : {(1,)}/{deltar.shape}\n","\"\"\")\n","\n","### init functions ### \n","from hwat_func import sample_b\n","\n","### train ###\n","import wandb\n","from hwat_func import keep_around_points\n","from utils import compute_metrix\n","from time import time\n","t0 = time()\n","\n","### add in optimiser\n","model = c.partial(Ansatz_fb).to(device)\n","opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","c.log_metric_step = 10\n","### fix sampler\n","### fix train step \n","### metrix conversion\n","model_fn, params = make_functional(model)\n","model_v = vmap(model_fn, in_dims=(None, 0))\n","\n","# print(c.wandb_c.)\n","wandb.define_metric(\"*\", step_metric=\"tr/step\")\n","print('Go see:', c._run.url)\n","v_tr = None\n","for step in range(1, c.n_step+1):\n","\tr_keep = r.clone()\n","\twith torch.no_grad():\n","     \n","     \n","\t\tmodel_fn, params = make_functional(model)\n","\t\tmodel_v = vmap(model_fn, in_dims=(None, 0))\n","\t\tmodel_rv = lambda _r: model_v(params, _r).sum()\n","\n","\t\tr, acc, deltar = sample_b(model_v, params, r, deltar, n_corr=c.data.n_corr)  # ‚ùóneeds testing  ‚úÖ\n","\t\tr = keep_around_points(r, center_points, l=2.) if step < 200 else r\n","\n","\t\t# with torch.no_grad():\n","\t\tke = compute_ke_b(model_rv, r)\n","\t\tpe = compute_pe_b(r, c.app.a, c.app.a_z)\n","\t\t# print(pe.shape, ke.shape)\n","\t\te = pe + ke\n","\t\te_mean_dist = torch.mean(torch.absolute(torch.median(e) - e))\n","\t\t# print(e.shape, e_mean_dist.shape)\n","\t\te_clip = torch.clip(e, min=e-5*e_mean_dist, max=e+5*e_mean_dist)\n","\n","\tmodel.zero_grad()\n","\topt.zero_grad()\n","\tloss = ((e_clip - e_clip.mean())*model_rv(r)).mean()\n","\tloss.backward()\n"," \n","\topt.step()\n","\n","\tv_tr = dict(\n","\t\te=e, \n","\t\tpe=pe,\n","\t\tke=ke,\n","\t\tr=r,\n","\t\tparams=params,\n","\t)\n","\n","\tif not (step % c.log_metric_step):\n","\t\tmetrix = compute_metrix(v_tr)  # ‚ùó needs converting to torch, ie tree maps ‚úÖ\n","\t\twandb.log({'tr/step':step, **metrix})\n","\t\n","\tdiff = time()-t0\n","\tif diff > 10: \n","\t\tt0 = time()\n","\t\tprint(torch.absolute(r - r_keep).sum())\n","\t\tprint(r[0][:2])\n","\t\tprint.print({k:f'{v.mean().item():.4f}' for k,v in v_tr.items() if isinstance(v, torch.Tensor)} | {'step': step})\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ```{toggle} env vars and jax debug config notes\n","# ‚ùáÔ∏è Magic & debug not currently used\n","\n","# %load_ext autoreload\n","# %autoreload 2\n","# %env CUDA_VISIBLE_DEVICES='3'\n","# %env \"WANDB_NOTEBOOK_NAME\" \"run.ipynb\" # ‚ùïsame as notebook\n","\n","# from jax.config import config\n","# config.update('jax_disable_jit', True)\n","# ```"]}],"metadata":{"kernelspec":{"display_name":"lumi","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0 (default, Nov 15 2020, 14:28:56) \n[GCC 7.3.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"6b38d4d910256a52431c1e658e4ec4972e8b118bd5f76052a504536bbce1f208"}},"deepnote_notebook_id":"2f5e8487-796e-4f87-b152-f82f7a3814da"},"nbformat":4,"nbformat_minor":2}