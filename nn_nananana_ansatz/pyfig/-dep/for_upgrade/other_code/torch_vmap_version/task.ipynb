{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2 "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pickle as pk\n","from jax import numpy as jnp\n","from jax import random as rnd\n","from flax.traverse_util import flatten_dict\n","\n","import torch \n","\n","from hwat_jax import FermiNet\n","from hwat_func import Ansatz_fb\n","\n","from pyfig import Pyfig\n","from utils import flat_any\n","from optree import tree_flatten"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['e', 'grads', 'ke', 'params', 'pe', 'r']) (1, 512, 4, 3) frozen_dict_keys(['params']) (512, 4, 3)\n"]}],"source":["# swap params\n","v_tr = pk.load(open('v_tr.pk', 'rb'))\n","v_params = v_tr['params']\n","v_grads = v_tr['grads']\n","r = v_tr['r']\n","# v_r = np.random.normal(0, 1, (n_b, n_e, 3))\n","print(v_tr.keys(), r.shape, v_params.keys(), r[0].shape)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-27 13:28:07.061537: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"]},{"name":"stdout","output_type":"stream","text":["init PlugIn classes\n","updating configuration\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: b90fa37 stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","running script\n","setting exp_path\n","Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: b90fa37 stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n"]},{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"name":"stdout","output_type":"stream","text":["Run: ['git', 'log', '--pretty=format:%h', '-n', '1'] at /home/amawi/projects/hwat\n","stdout: b90fa37 stderr: \n","Run: ['hostname'] at .\n","stdout: oceanus  stderr: \n","('params', 'Dense_0', 'bias') (1, 32) ('params', 'Dense_0', 'bias') (32,)\n","('params', 'Dense_0', 'kernel') (1, 20, 32) ('params', 'Dense_0', 'kernel') (20, 32)\n","('params', 'Dense_1', 'bias') (1, 32) ('params', 'Dense_1', 'bias') (16,)\n","('params', 'Dense_1', 'kernel') (1, 4, 32) ('params', 'Dense_1', 'kernel') (4, 16)\n","('params', 'Dense_2', 'bias') (1, 32) ('params', 'Dense_2', 'bias') (32,)\n","('params', 'Dense_2', 'kernel') (1, 160, 32) ('params', 'Dense_2', 'kernel') (128, 32)\n","('params', 'Dense_3', 'bias') (1, 16) ('params', 'Dense_3', 'bias') (16,)\n","('params', 'Dense_3', 'kernel') (1, 32, 16) ('params', 'Dense_3', 'kernel') (32, 16)\n","('params', 'Dense_4', 'bias') (1, 16) ('params', 'Dense_4', 'bias') (16,)\n","('params', 'Dense_4', 'kernel') (1, 32, 16) ('params', 'Dense_4', 'kernel') (32, 16)\n","('params', 'Dense_5', 'bias') (1, 2) ('params', 'Dense_5', 'bias') (2,)\n","('params', 'Dense_5', 'kernel') (1, 16, 2) ('params', 'Dense_5', 'kernel') (16, 2)\n","('params', 'Dense_6', 'bias') (1, 2) ('params', 'Dense_6', 'bias') (2,)\n","('params', 'Dense_6', 'kernel') (1, 16, 2) ('params', 'Dense_6', 'kernel') (16, 2)\n","[-14.439759 -12.577759]\n","frozen_dict_keys(['Dense_0', 'Dense_1', 'Dense_2', 'Dense_3', 'Dense_4', 'Dense_5', 'Dense_6']) frozen_dict_keys(['Dense_0', 'Dense_1', 'Dense_2', 'Dense_3', 'Dense_4', 'Dense_5', 'Dense_6'])\n"]}],"source":["rng = rnd.PRNGKey(1)\n","cj = Pyfig(wb_mode='disabled', notebook=True)\n","jmod = cj.partial(FermiNet)\n","_jp = jmod.init(rng, r[0, [0]])\n","jp = v_params\n","for (k, p), (_k, _p) in zip(flatten_dict(jp).items(), flatten_dict(_jp).items()):\n","    print(k, p.shape, _k, _p.shape)\n","log_psi = jmod.apply(_jp, r[0])\n","print(log_psi[:2])\n","print(v_params['params'].keys(), _jp['params'].keys())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(('params', 'Dense_0', 'bias'),\n"," Array([0.00593489, 0.00268932, 0.00064195, 0.00706287, 0.00621831,\n","        0.00998503, 0.00726382, 0.00146654, 0.00408086, 0.00807343,\n","        0.00637496, 0.00919925, 0.00673006, 0.00812667, 0.00376891,\n","        0.00985797, 0.00689847, 0.00966867, 0.00270503, 0.00158928,\n","        0.00351574, 0.00832261, 0.00841896, 0.00154599, 0.00474995,\n","        0.00800335, 0.00841118, 0.00508559, 0.00370565, 0.00682438,\n","        0.00971892, 0.00518902], dtype=float32))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["list(flatten_dict(_jp).items())[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","tdtype = torch.float64\n","c = Pyfig(wb_mode='disabled', notebook=True)\n","c._convert(device='cpu', dtype=tdtype)\n","n_b, n_e = c.data.n_b, c.data.n_e\n","torch.set_default_dtype(tdtype)\n","tr = torch.tensor(r, dtype=tdtype)\n","\n","tmod = c.partial(Ansatz_fb).to(tdtype)\n","tp = list(tmod.named_parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","def swap_params(jp, tp):\n","    jp_flat = flatten_dict(jp)\n","    print(len(jp_flat), len(tp))\n","    jp_b = [(k, jp0) for (k, jp0) in  jp_flat.items() if 'bias' in k]\n","    tp_b = [(k, jp0) for (k, jp0) in  tp if 'bias' in k]\n","    jp_p = [(k, jp0) for (k, jp0) in  jp_flat.items() if 'kernel' in k]\n","    tp_p = [(k, jp0) for (k, jp0) in  tp if 'weight' in k]\n","\n","    order = [0, 2, 1] + [i for i in range(3, 9)]\n","    key = {jp_b[i][0]:tp_b[j][0] for j, i in enumerate(order)} | {jp_p[i][0]:tp_p[j][0] for j, i in enumerate(order)}\n","    jp_b = [jp_b[i] for i in order]\n","    jp_p = [jp_p[i] for i in order]\n","    new_tp = {tp_b[i][0] : np.array(b[1]) for i,b in enumerate(jp_b)} | {tp_p[i][0] : np.array(p[1]).T for i,p in enumerate(jp_p)}\n","\n","    # print(len(jp_flat), len(tp))\n","    # for (k, jp0), (tpk, tp0) in zip(jp_b, tp_b):\n","    #     print('.'.join(k).replace('kernel', 'weight'), tpk, jp0.shape, tp0.shape)\n","        \n","    # print(len(jp_flat), len(tp))\n","    # for (k, jp0), (tpk, tp0) in zip(jp_p, tp_p):\n","    #     print('.'.join(k).replace('kernel', 'weight'), tpk, jp0.shape, tp0.shape)\n","    return new_tp, key\n","\n","new_tp, key = swap_params(jp, tp)\n","for name, param in tmod.named_parameters():\n","    # print(name)\n","    # print(param.data.dtype, param.data.shape)\n","    param.data = torch.tensor(new_tp[name], requires_grad=True, dtype=tdtype)\n","    # print(param.data.dtype, param.data.shape)"]}],"metadata":{"kernelspec":{"display_name":"lumi","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0 (default, Nov 15 2020, 14:28:56) \n[GCC 7.3.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"6b38d4d910256a52431c1e658e4ec4972e8b118bd5f76052a504536bbce1f208"}},"deepnote_notebook_id":"3d97f8c1-df30-4d9d-9ba6-05d1bdb15159"},"nbformat":4,"nbformat_minor":2}